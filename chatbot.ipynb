{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6, openai_api_key = os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The capital of Pakistan is Islamabad.\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the capital of Pakistan?\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Work\\Chatbot OpenAI Langchain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Work\\Chatbot OpenAI Langchain\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "llm_huggingface = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\": 0.6, \"max_length\": 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "print(llm_huggingface.predict(\"What is the capital of Russia?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love my dog he is so sweet he always tries to get my attention he always tries to get my attention he always tries to get my attention he always tries to get my attention he always tries to get my attention he always tries to get my\n"
     ]
    }
   ],
   "source": [
    "print(llm_huggingface.predict(\"Write a poem a poem about a dog.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A loyal friend with four paws,\n",
      "A furry companion with no flaws,\n",
      "A dog, a creature of pure love,\n",
      "Sent to us from the heavens above.\n",
      "\n",
      "With eyes so bright and full of glee,\n",
      "They fill our hearts with endless glee,\n",
      "Their wagging tails and happy barks,\n",
      "Can chase away even the darkest of marks.\n",
      "\n",
      "They greet us with excitement each day,\n",
      "No matter what troubles come our way,\n",
      "Their love is unconditional and true,\n",
      "A bond that forever will renew.\n",
      "\n",
      "They run and play with endless joy,\n",
      "A ball, a stick, their favorite toy,\n",
      "Their energy and spirit never fade,\n",
      "A constant reminder of the joy they've made.\n",
      "\n",
      "They snuggle close when we are sad,\n",
      "Their comforting presence is all we need,\n",
      "They listen without judgment or words,\n",
      "Their empathy is beyond what can be heard.\n",
      "\n",
      "From big to small, from old to young,\n",
      "Their love and loyalty is never undone,\n",
      "They are more than just a pet,\n",
      "They are family, they are our greatest asset.\n",
      "\n",
      "So here's to the dogs, our faithful friends,\n",
      "Our hearts they will forever mend,\n",
      "For they are more than just a pet,\n",
      "They are love, they are our greatest asset.\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict(\"Write a poem a poem about a dog.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(input_variables=[\"country\"],\n",
    "                                    template=\"What is the capital of {country}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of Pakistan is Islamabad.\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm = llm, prompt = prompt_template)\n",
    "print(chain.run(\"Pakistan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=[\"country\"], template=\"What is the capital of {country}?\")\n",
    "capital_chain = LLMChain(llm = llm, prompt = capital_template)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=[\"capital\"], template=\"What is the most famous thing about {capital}?\")\n",
    "famous_chain = LLMChain(llm = llm, prompt = famous_template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The most famous thing about Islamabad, the capital of Pakistan, is its beautiful and modern architecture, including the iconic Faisal Mosque. It is also known for being a planned city with greenery and natural beauty, as well as being home to various government buildings and diplomatic missions.\n"
     ]
    }
   ],
   "source": [
    "chain = SimpleSequentialChain(chains=[capital_chain, famous_chain])\n",
    "print(chain.run(\"Pakistan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=[\"country\"], template=\"What is the capital of {country}?\")\n",
    "capital_chain = LLMChain(llm = llm, prompt = capital_template, output_key=\"capital\")\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=[\"capital\"], template=\"What is the most famous thing about {capital}?\")\n",
    "famous_chain = LLMChain(llm = llm, prompt = famous_template, output_key=\"famous\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SequentialChain(chains=[capital_chain, famous_chain], input_variables=[\"country\"], output_variables=[\"capital\",\"famous\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'Pakistan',\n",
       " 'capital': '\\n\\nThe capital of Pakistan is Islamabad. ',\n",
       " 'famous': '\\n\\nThe most famous thing about Islamabad is its modern and planned city layout, which includes wide roads, green spaces, and beautiful architecture. It is also known for being the political and administrative center of Pakistan, housing important government buildings such as the Parliament House and the Supreme Court. Additionally, Islamabad is known for its scenic location at the foot of the Margalla Hills and its proximity to popular tourist destinations such as the Faisal Mosque and Rawal Lake.'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"Pakistan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatOpenAI(temperature=0.6, openai_api_key = os.environ[\"OPENAI_API_KEY\"], model = \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"Why did the AI become a stand-up comedian? Because it could always compute the perfect punchline!\"\\n\\n2. \"I asked Siri if she had any jokes, and she said, \\'Why did the robot go on a diet? It had too many bytes!\\'\"\\n\\n3. \"Artificial intelligence is like a bad comedian... always trying to \\'compute\\' the audience!\"\\n\\n4. \"Why did the AI fail at comedy? It couldn\\'t understand the concept of \\'timing\\'... it was always \\'processing\\'!\"\\n\\n5. \"I told my AI assistant I wanted to hear a joke, and it replied, \\'Why don\\'t scientists trust atoms? Because they make up everything!\\' Looks like AI has a sense of humor... or maybe it\\'s just programmed to laugh at dad jokes!\"\\n\\n6. \"I asked Google Assistant if it could make me laugh, and it replied, \\'Why did the computer go to the doctor? Because it had a virus!\\' Well, at least it\\'s got a sense of humor... even if it\\'s a bit \\'byte\\'-sized!\"\\n\\n7. \"Why did the AI go to therapy? It had too many unresolved \\'binary\\' issues!\"\\n\\n8. \"I asked Alexa to tell me a joke, and she said, \\'Why don\\'t robots ever eat clocks? Because it\\'s too time-consuming!\\' I guess even AI knows that some jokes are just \\'tick\\'-lish!\"\\n\\n9. \"Why did the AI cross the road? To optimize its algorithm for efficient pedestrian navigation!\"\\n\\n10. \"I asked my AI assistant if it could tell me a joke, and it replied, \\'Why did the computer go to the party? Because it had a lot of cache!\\' Well, at least it\\'s got a good \\'memory\\' for humor!\"')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm([\n",
    "    SystemMessage(content = \"You are a comdian AI assistant.\"),\n",
    "    HumanMessage(content = \"Please provide some comedy punchlines on AI.\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeparatedParser(BaseOutputParser):\n",
    "    def parse(self, output:str):\n",
    "        return output.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant. When the user gives any input, you should generate 5 synonym words in a comma seperated list.\"\n",
    "human_template = \"{text}\"\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt|chat_llm|CommaSeparatedParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' brilliant', ' knowledgeable', ' astute']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
